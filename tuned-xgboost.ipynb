{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3330fc8c-81a5-4627-adbc-6259481cd881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_29248\\3647235274.py:15: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/train/cleaned_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Hyperparameters: {'model__colsample_bytree': np.float64(0.9244569121330419), 'model__learning_rate': np.float64(0.22651885634946198), 'model__max_depth': 9, 'model__n_estimators': 191, 'model__reg_alpha': np.float64(0.49379559636439074), 'model__reg_lambda': np.float64(0.5227328293819941), 'model__subsample': np.float64(0.7137705091792748)}\n",
      "Results saved to models/optimized_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "from feature_hasher_transformer import FeatureHasherTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from feature_hasher_transformer import FeatureHasherTransformer\n",
    "import joblib\n",
    "\n",
    "\n",
    "# 1) LOAD + PREPROCESS TRAIN DATA\n",
    "df = pd.read_csv(\"data/train/cleaned_data.csv\")\n",
    "\n",
    "# (a) Drop any row where material_price is missing or ≤0\n",
    "df = df.dropna(subset=['material_price'])\n",
    "df = df[df['material_price'] > 0]\n",
    "\n",
    "# (b) Fill missing text columns (including surname and action)\n",
    "text_columns_train = [\n",
    "    'material_name',\n",
    "    'material_type',\n",
    "    'material_subtype',\n",
    "    'surgeon_name',\n",
    "    'surgeon_surname',\n",
    "    'procedure_name'\n",
    "]\n",
    "df[text_columns_train] = df[text_columns_train].fillna('missing').astype(str)\n",
    "\n",
    "# We also assume there is a column called 'surgeon_specific_action' in cleaned_data.csv,\n",
    "# whose values are \"ADDED\" or \"DEFAULT\". Fill any missing with 'missing' too:\n",
    "df['surgeon_specific_action'] = df['surgeon_specific_action'].fillna('missing').astype(str)\n",
    "\n",
    "# (c) Create combined “surgeon_fullname” from name + surname\n",
    "df['surgeon_fullname'] = (\n",
    "    df['surgeon_name'].str.strip() + ' ' + df['surgeon_surname'].str.strip()\n",
    ")\n",
    "\n",
    "# (d) Normalize material_name to lowercase to match test_data\n",
    "df['material_name'] = df['material_name'].str.lower()\n",
    "\n",
    "# (e) Combine text features for hashing\n",
    "df['combined_features'] = df[\n",
    "    ['material_name', \n",
    "     'material_type', \n",
    "     'material_subtype',\n",
    "     'surgeon_fullname', \n",
    "     'procedure_name']\n",
    "].agg(' '.join, axis=1)\n",
    "\n",
    "# (f) Log-transform the target\n",
    "y_log = np.log(df['material_price'].values)\n",
    "\n",
    "\n",
    "# 2) BUILD LOOKUP: (material_name, surgeon_fullname) → (material_price, surgeon_specific_action)\n",
    "# Keep only the first unique (material_name, surgeon_fullname)––that row’s material_price + action\n",
    "lookup = (\n",
    "    df[['material_name', 'surgeon_fullname', 'material_price', 'surgeon_specific_action']]\n",
    "      .drop_duplicates(subset=['material_name', 'surgeon_fullname'], keep='first')\n",
    "      .rename(columns={\n",
    "          'surgeon_fullname':          'train_surgeon_fullname',\n",
    "          'material_price':            'train_material_price',\n",
    "          'surgeon_specific_action':   'train_surgeon_specific_action'\n",
    "      })\n",
    ")\n",
    "# Now `lookup` has columns:\n",
    "#    [material_name, train_surgeon_fullname, train_material_price, train_surgeon_specific_action]\n",
    "\n",
    "# 3) TRAIN/TEST SPLIT for the MODEL\n",
    "X_train_text, X_test_text, y_train_log, y_test_log = train_test_split(\n",
    "    df['combined_features'], \n",
    "    y_log, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('hasher', FeatureHasherTransformer(n_features=100)),\n",
    "    ('model', XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'model__n_estimators':     randint(50, 300),\n",
    "    'model__max_depth':        randint(3, 10),\n",
    "    'model__learning_rate':    uniform(0.01, 0.3),\n",
    "    'model__subsample':        uniform(0.5, 0.5),\n",
    "    'model__colsample_bytree': uniform(0.5, 0.5),\n",
    "    'model__reg_alpha':        uniform(0, 1),\n",
    "    'model__reg_lambda':       uniform(0, 1),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train_text, y_train_log)\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "\n",
    "# 4) OPTIMIZATION ON TEST SET + MERGE LOOKUP\n",
    "# (a) Build dict of material → min price (for get_cheapest_price)\n",
    "historical_min_prices = df.groupby('material_name')['material_price'].min().to_dict()\n",
    "\n",
    "# (b) Load test_data\n",
    "test_data = pd.read_csv('data/test/new_data.csv', low_memory=False)\n",
    "\n",
    "# (c) Fill missing test‐side text columns (including surname and action)\n",
    "text_columns_test = [\n",
    "    'material_name', \n",
    "    'material_type', \n",
    "    'material_subtype',\n",
    "    'surgeon_name',   \n",
    "    'surgeon_surname', \n",
    "    'procedure_name'\n",
    "]\n",
    "test_data[text_columns_test] = test_data[text_columns_test].fillna('missing').astype(str)\n",
    "\n",
    "# We assume test_data also has a column 'surgeon_specific_action';\n",
    "# if not, you can drop or rename accordingly:\n",
    "test_data['surgeon_specific_action'] = test_data['surgeon_specific_action'].fillna('missing').astype(str)\n",
    "\n",
    "# (d) Create combined “surgeon_fullname” in test_data\n",
    "test_data['surgeon_fullname'] = (\n",
    "    test_data['surgeon_name'].str.strip() + ' ' + test_data['surgeon_surname'].str.strip()\n",
    ")\n",
    "\n",
    "# (e) Normalize material_name\n",
    "test_data['material_name'] = test_data['material_name'].str.lower()\n",
    "\n",
    "# (f) Rebuild combined_features for hashing\n",
    "test_data['combined_features'] = test_data[\n",
    "    ['material_name', \n",
    "     'material_type', \n",
    "     'material_subtype',\n",
    "     'surgeon_fullname', \n",
    "     'procedure_name']\n",
    "].agg(' '.join, axis=1)\n",
    "\n",
    "# (g) Create is_default flag exactly as before\n",
    "test_data['is_default'] = (test_data['surgeon_name'] == 'Standardized').astype(int)\n",
    "\n",
    "# (h) Ensure no new material is missing from historical_min_prices\n",
    "missing_materials = set(test_data['material_name']) - set(historical_min_prices.keys())\n",
    "if missing_materials:\n",
    "    raise ValueError(f\"Materials {missing_materials} not found in cleaned_data.csv\")\n",
    "\n",
    "# (i) Map the “min‐price” for optimization logic\n",
    "test_data['material_price'] = test_data['material_name'].map(historical_min_prices)\n",
    "\n",
    "# (j) Merge in the “original” train‐file info (price + action) \n",
    "#     by matching on (material_name, surgeon_fullname)\n",
    "test_data = test_data.merge(\n",
    "    lookup,\n",
    "    left_on=['material_name', 'surgeon_fullname'],\n",
    "    right_on=['material_name', 'train_surgeon_fullname'],\n",
    "    how='left'\n",
    ")\n",
    "# Now test_data has columns:\n",
    "#    … , 'train_surgeon_fullname', 'train_material_price', 'train_surgeon_specific_action', …\n",
    "\n",
    "# (k) Predict & back‐transform\n",
    "log_preds = best_model.predict(test_data['combined_features'])\n",
    "test_data['predicted_price'] = np.exp(log_preds)\n",
    "\n",
    "# (l) Ensure predicted_price ≥ overall train‐min\n",
    "min_train_price = df['material_price'].min()\n",
    "test_data['predicted_price'] = np.clip(test_data['predicted_price'], min_train_price, None)\n",
    "\n",
    "# (m) Helper to pick the “cheapest” (min from df)\n",
    "def get_cheapest_price(row):\n",
    "    hist_price = row['material_price']  # this is the MIN from df\n",
    "    if not np.isnan(hist_price):\n",
    "        return hist_price, 'historical'\n",
    "    else:\n",
    "        raise ValueError(f\"No historical price found for material {row['material_name']}\")\n",
    "\n",
    "# (n) Build final results\n",
    "results = []\n",
    "for proc_id in test_data['procedure_id'].unique():\n",
    "    proc_data = test_data[test_data['procedure_id'] == proc_id].copy()\n",
    "\n",
    "    # Identify default and surgeon-added materials\n",
    "    default_data = proc_data[proc_data['is_default'] == 1]\n",
    "    default_materials = set(default_data['material_name'])\n",
    "    surgeon_data = proc_data[proc_data['is_default'] == 0]\n",
    "    surgeon_added = set(\n",
    "        surgeon_data[surgeon_data['surgeon_specific_action'] != 'default']['material_name']\n",
    "    ) - default_materials\n",
    "    all_materials = default_materials.union(surgeon_added)\n",
    "\n",
    "    # Compute original total cost for the procedure\n",
    "    orig_prices_list = []\n",
    "    for mat in all_materials:\n",
    "        rows = proc_data[proc_data['material_name'] == mat]\n",
    "        if not rows.empty:\n",
    "            orig_prices_list.append(rows.iloc[0]['train_material_price'])\n",
    "    procedure_original_cost = sum(orig_prices_list)\n",
    "\n",
    "    # Gather optimized materials info\n",
    "    optimized_materials = {}\n",
    "    for mat in all_materials:\n",
    "        rows = proc_data[proc_data['material_name'] == mat]\n",
    "        if rows.empty:\n",
    "            continue\n",
    "        row0 = rows.iloc[0]\n",
    "        # Get cheapest historical price\n",
    "        cheapest_price = historical_min_prices.get(mat, np.nan)\n",
    "        # Collect new fields\n",
    "        material_id = row0.get('material_id')\n",
    "        material_type = row0.get('material_type')\n",
    "        material_subtype = row0.get('material_subtype')\n",
    "        specialty = row0.get('speciality')  # rename to 'specialty'\n",
    "        procedure_name = row0.get('procedure_name')\n",
    "        # Original train info\n",
    "        surgeon_fullname = row0['train_surgeon_fullname']\n",
    "        surgeon_specific_action = row0['train_surgeon_specific_action']\n",
    "\n",
    "        optimized_materials[mat] = {\n",
    "            'material_id': material_id,\n",
    "            'material_name': mat,\n",
    "            'material_original_price': row0['train_material_price'],\n",
    "            'material_optimized_price': cheapest_price,\n",
    "            'material_type': material_type,\n",
    "            'material_subtype': material_subtype,\n",
    "            'specialty': specialty,\n",
    "            'procedure_id': proc_id,\n",
    "            'procedure_name': procedure_name,\n",
    "            'procedure_original_cost': procedure_original_cost,\n",
    "            'price_source': 'historical' if not np.isnan(cheapest_price) else 'none',\n",
    "            'surgeon_fullname': surgeon_fullname,\n",
    "            'surgeon_specific_action': surgeon_specific_action\n",
    "        }\n",
    "\n",
    "    # Compute optimized cost for the procedure\n",
    "    procedure_optimized_cost = sum(\n",
    "        info['material_optimized_price'] for info in optimized_materials.values() if not np.isnan(info['material_optimized_price'])\n",
    "    )\n",
    "\n",
    "    # Append to results with final cost assigned\n",
    "    for mat, info in optimized_materials.items():\n",
    "        row = info.copy()\n",
    "        # add procedure_optimized_cost\n",
    "        row['procedure_optimized_cost'] = procedure_optimized_cost\n",
    "        results.append(row)\n",
    "\n",
    "# Convert to DataFrame and reorder columns\n",
    "columns_order = [\n",
    "    'material_id', 'material_name', 'material_original_price', 'material_optimized_price',\n",
    "    'material_type', 'material_subtype', 'specialty', 'procedure_id', 'procedure_name',\n",
    "    'procedure_original_cost', 'procedure_optimized_cost', 'price_source',\n",
    "    'surgeon_fullname', 'surgeon_specific_action'\n",
    "]\n",
    "results_df = pd.DataFrame(results)[columns_order]\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('models/optimized_results.csv', index=False)\n",
    "\n",
    "# Save lookup and model as before\n",
    "joblib.dump(lookup, 'models/lookup.joblib')\n",
    "joblib.dump(historical_min_prices, 'models/min_prices.joblib')\n",
    "joblib.dump(best_model, 'models/model_weights.joblib')\n",
    "\n",
    "print('Results saved to models/optimized_results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
