{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3330fc8c-81a5-4627-adbc-6259481cd881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19564\\3606242596.py:17: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/train/cleaned_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Hyperparameters: {'model__colsample_bytree': np.float64(0.9244569121330419), 'model__learning_rate': np.float64(0.22651885634946198), 'model__max_depth': 9, 'model__n_estimators': 191, 'model__reg_alpha': np.float64(0.49379559636439074), 'model__reg_lambda': np.float64(0.5227328293819941), 'model__subsample': np.float64(0.7137705091792748)}\n",
      " Dumped lookup, min_prices, and model to /models/*.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from xgboost import XGBRegressor\n",
    "from collections import Counter\n",
    "from scipy.stats import uniform, randint\n",
    "from feature_hasher_transformer import FeatureHasherTransformer\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 1) LOAD + PREPROCESS TRAIN DATA\n",
    "# ================================\n",
    "df = pd.read_csv(\"data/train/cleaned_data.csv\")\n",
    "\n",
    "# (a) Drop any row where material_price is missing or ≤0\n",
    "df = df.dropna(subset=['material_price'])\n",
    "df = df[df['material_price'] > 0]\n",
    "\n",
    "# (b) Fill missing text columns (including surname and action)\n",
    "text_columns_train = [\n",
    "    'material_name',\n",
    "    'material_type',\n",
    "    'material_subtype',\n",
    "    'surgeon_name',\n",
    "    'surgeon_surname',\n",
    "    'procedure_name'\n",
    "]\n",
    "df[text_columns_train] = df[text_columns_train].fillna('missing').astype(str)\n",
    "\n",
    "# We also assume there is a column called 'surgeon_specific_action' in cleaned_data.csv,\n",
    "# whose values are \"ADDED\" or \"DEFAULT\". Fill any missing with 'missing' too:\n",
    "df['surgeon_specific_action'] = df['surgeon_specific_action'].fillna('missing').astype(str)\n",
    "\n",
    "# (c) Create combined “surgeon_fullname” from name + surname\n",
    "df['surgeon_fullname'] = (\n",
    "    df['surgeon_name'].str.strip() + ' ' + df['surgeon_surname'].str.strip()\n",
    ")\n",
    "\n",
    "# (d) Normalize material_name to lowercase to match test_data\n",
    "df['material_name'] = df['material_name'].str.lower()\n",
    "\n",
    "# (e) Combine text features for hashing\n",
    "df['combined_features'] = df[\n",
    "    ['material_name', \n",
    "     'material_type', \n",
    "     'material_subtype',\n",
    "     'surgeon_fullname', \n",
    "     'procedure_name']\n",
    "].agg(' '.join, axis=1)\n",
    "\n",
    "# (f) Log-transform the target\n",
    "y_log = np.log(df['material_price'].values)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) BUILD LOOKUP: (material_name, surgeon_fullname) → (material_price, surgeon_specific_action)\n",
    "# ------------------------------------------------\n",
    "# Keep only the first unique (material_name, surgeon_fullname)––that row’s material_price + action\n",
    "lookup = (\n",
    "    df[['material_name', 'surgeon_fullname', 'material_price', 'surgeon_specific_action']]\n",
    "      .drop_duplicates(subset=['material_name', 'surgeon_fullname'], keep='first')\n",
    "      .rename(columns={\n",
    "          'surgeon_fullname':          'train_surgeon_fullname',\n",
    "          'material_price':            'train_material_price',\n",
    "          'surgeon_specific_action':   'train_surgeon_specific_action'\n",
    "      })\n",
    ")\n",
    "# Now `lookup` has columns:\n",
    "#    [material_name, train_surgeon_fullname, train_material_price, train_surgeon_specific_action]\n",
    "\n",
    "# ===================================\n",
    "# 3) TRAIN/TEST SPLIT for the MODEL\n",
    "# ===================================\n",
    "X_train_text, X_test_text, y_train_log, y_test_log = train_test_split(\n",
    "    df['combined_features'], \n",
    "    y_log, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('hasher', FeatureHasherTransformer(n_features=100)),\n",
    "    ('model', XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'model__n_estimators':     randint(50, 300),\n",
    "    'model__max_depth':        randint(3, 10),\n",
    "    'model__learning_rate':    uniform(0.01, 0.3),\n",
    "    'model__subsample':        uniform(0.5, 0.5),\n",
    "    'model__colsample_bytree': uniform(0.5, 0.5),\n",
    "    'model__reg_alpha':        uniform(0, 1),\n",
    "    'model__reg_lambda':       uniform(0, 1),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train_text, y_train_log)\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# ===========================================\n",
    "# 4) OPTIMIZATION ON TEST SET + MERGE LOOKUP\n",
    "# ===========================================\n",
    "# (a) Build dict of material → min price (for get_cheapest_price)\n",
    "historical_min_prices = df.groupby('material_name')['material_price'].min().to_dict()\n",
    "\n",
    "# (b) Load test_data\n",
    "test_data = pd.read_csv('data/test/new_data.csv', low_memory=False)\n",
    "\n",
    "# (c) Fill missing test‐side text columns (including surname and action)\n",
    "text_columns_test = [\n",
    "    'material_name', \n",
    "    'material_type', \n",
    "    'material_subtype',\n",
    "    'surgeon_name',   \n",
    "    'surgeon_surname', \n",
    "    'procedure_name'\n",
    "]\n",
    "test_data[text_columns_test] = test_data[text_columns_test].fillna('missing').astype(str)\n",
    "\n",
    "# We assume test_data also has a column 'surgeon_specific_action';\n",
    "# if not, you can drop or rename accordingly:\n",
    "test_data['surgeon_specific_action'] = test_data['surgeon_specific_action'].fillna('missing').astype(str)\n",
    "\n",
    "# (d) Create combined “surgeon_fullname” in test_data\n",
    "test_data['surgeon_fullname'] = (\n",
    "    test_data['surgeon_name'].str.strip() + ' ' + test_data['surgeon_surname'].str.strip()\n",
    ")\n",
    "\n",
    "# (e) Normalize material_name\n",
    "test_data['material_name'] = test_data['material_name'].str.lower()\n",
    "\n",
    "# (f) Rebuild combined_features for hashing\n",
    "test_data['combined_features'] = test_data[\n",
    "    ['material_name', \n",
    "     'material_type', \n",
    "     'material_subtype',\n",
    "     'surgeon_fullname', \n",
    "     'procedure_name']\n",
    "].agg(' '.join, axis=1)\n",
    "\n",
    "# (g) Create is_default flag exactly as before\n",
    "test_data['is_default'] = (test_data['surgeon_name'] == 'Standardized').astype(int)\n",
    "\n",
    "# (h) Ensure no new material is missing from historical_min_prices\n",
    "missing_materials = set(test_data['material_name']) - set(historical_min_prices.keys())\n",
    "if missing_materials:\n",
    "    raise ValueError(f\"Materials {missing_materials} not found in cleaned_data.csv\")\n",
    "\n",
    "# (i) Map the “min‐price” for optimization logic\n",
    "test_data['material_price'] = test_data['material_name'].map(historical_min_prices)\n",
    "\n",
    "# (j) Merge in the “original” train‐file info (price + action) \n",
    "#     by matching on (material_name, surgeon_fullname)\n",
    "test_data = test_data.merge(\n",
    "    lookup,\n",
    "    left_on=['material_name', 'surgeon_fullname'],\n",
    "    right_on=['material_name', 'train_surgeon_fullname'],\n",
    "    how='left'\n",
    ")\n",
    "# Now test_data has columns:\n",
    "#    … , 'train_surgeon_fullname', 'train_material_price', 'train_surgeon_specific_action', …\n",
    "\n",
    "# (k) Predict & back‐transform\n",
    "log_preds = best_model.predict(test_data['combined_features'])\n",
    "test_data['predicted_price'] = np.exp(log_preds)\n",
    "\n",
    "# (l) Ensure predicted_price ≥ overall train‐min\n",
    "min_train_price = df['material_price'].min()\n",
    "test_data['predicted_price'] = np.clip(test_data['predicted_price'], min_train_price, None)\n",
    "\n",
    "# (m) Helper to pick the “cheapest” (min from df)\n",
    "def get_cheapest_price(row):\n",
    "    hist_price = row['material_price']  # this is the MIN from df\n",
    "    if not np.isnan(hist_price):\n",
    "        return hist_price, 'historical'\n",
    "    else:\n",
    "        raise ValueError(f\"No historical price found for material {row['material_name']}\")\n",
    "\n",
    "# (n) Build final results, now including:\n",
    "#     •  train_surgeon_fullname  \n",
    "#     •  train_material_price    \n",
    "#     •  train_surgeon_specific_action  \n",
    "#     •  optimized_price      \n",
    "#     •  original_total_cost \n",
    "results = []\n",
    "for proc_id in test_data['procedure_id'].unique():\n",
    "    proc_data = test_data[test_data['procedure_id'] == proc_id].copy()\n",
    "\n",
    "    default_data = proc_data[proc_data['is_default'] == 1]\n",
    "    default_materials = set(default_data['material_name'])\n",
    "\n",
    "    surgeon_data = proc_data[proc_data['is_default'] == 0]\n",
    "    surgeon_added = set(\n",
    "        surgeon_data[surgeon_data['surgeon_specific_action'] != 'default']['material_name']\n",
    "    ) - default_materials\n",
    "    all_materials = default_materials.union(surgeon_added)\n",
    "\n",
    "    # 1) Compute original_total_cost = sum of train_material_price for all materials in this proc\n",
    "    orig_prices_list = []\n",
    "    for mat in all_materials:\n",
    "        mat_rows = proc_data[proc_data['material_name'] == mat]\n",
    "        if not mat_rows.empty:\n",
    "            row0 = mat_rows.iloc[0]\n",
    "            orig_prices_list.append(row0['train_material_price'])\n",
    "    original_total_cost = sum(orig_prices_list)\n",
    "\n",
    "    # 2) Build optimized_materials dictionary as before\n",
    "    optimized_materials = {}\n",
    "    for mat in all_materials:\n",
    "        mat_rows = proc_data[proc_data['material_name'] == mat]\n",
    "        if not mat_rows.empty:\n",
    "            cheapest_row = mat_rows.iloc[0]\n",
    "\n",
    "            # (a) optimized_price = cheapest (min) from df\n",
    "            cheapest_price, price_source = get_cheapest_price(cheapest_row)\n",
    "\n",
    "            # (b) pull the train‐file surgeon_fullname, original price, and action\n",
    "            orig_surgeon_fullname  = cheapest_row['train_surgeon_fullname']\n",
    "            orig_price             = cheapest_row['train_material_price']\n",
    "            orig_action            = cheapest_row['train_surgeon_specific_action']\n",
    "\n",
    "            optimized_materials[mat] = (\n",
    "                cheapest_price,            # → optimized_price\n",
    "                price_source,\n",
    "                orig_surgeon_fullname,     # → combined surgeon name\n",
    "                orig_price,                # → original price\n",
    "                orig_action                # → “ADDED” or “DEFAULT”\n",
    "            )\n",
    "\n",
    "    optimized_cost = sum(val[0] for val in optimized_materials.values())\n",
    "\n",
    "    # 3) Append rows to results; include all new fields\n",
    "    for mat, (opt_price, source, orig_surgeon_fullname, orig_price, orig_action) in optimized_materials.items():\n",
    "        results.append({\n",
    "            'procedure_id':                 proc_id,\n",
    "            'material_name':                mat,\n",
    "            'surgeon_fullname_train':       orig_surgeon_fullname,\n",
    "            'original_price_train':         orig_price,\n",
    "            'surgeon_specific_action_train':orig_action,\n",
    "            'original_total_cost':          original_total_cost,\n",
    "            'optimized_price':              opt_price,\n",
    "            'price_source':                 source,\n",
    "            'optimized_cost':               optimized_cost\n",
    "        })\n",
    "\n",
    "import joblib\n",
    "# 1) Save the “lookup” DataFrame\n",
    "joblib.dump(lookup, \"models/lookup.joblib\")\n",
    "\n",
    "# 2) Save the historical-min dict\n",
    "joblib.dump(historical_min_prices, \"models/min_prices.joblib\")\n",
    "\n",
    "# 3) (Optionally) Save your trained model/pipeline\n",
    "joblib.dump(best_model, \"models/model_weights.joblib\")\n",
    "\n",
    "print(\" Dumped lookup, min_prices, and model to /models/*.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
